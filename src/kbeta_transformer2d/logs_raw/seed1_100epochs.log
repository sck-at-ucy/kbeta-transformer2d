mx‑Random: [array([0, 1], dtype=uint32)]
Random state: [array([0, 1], dtype=uint32)]
Configuration: base_case:block
Hostname: PaloAlto: DYLD_LIBRARY_PATH:None
Random state: [array([0, 1], dtype=uint32)]
Configuration: base_case:block
Hostname: PaloAlto: DYLD_LIBRARY_PATH:None
All generated and saved datasets match.
training data shape: (2800, 401, 26, 26)
validation data shape: (800, 401, 26, 26)
<kourkoutas.Kourkoutas_optimizer.KourkoutasSoftmaxFlex object at 0x179a0c4d0>
KOUR  β1=0.9 | β2_max=0.999 | β2_min=0.88 | α=0.93 | tiny=1.00e-08 | tiny=1.00e-08 | adaptT=False | decay=off | maxR=off | warmup=350 | eps=1.00e-08
 ===== Current Configuration for Fresh Run ====
 ----  Ensure everything is correct before starting ----
Config Key               
==================================================
boundary_conditions      
  Current Config: {'left_limits': [0, 1], 'right_limits': [0, 1], 'top_limits': [0, 1], 'bottom_limits': [0, 0.1]}
--------------------------------------------------
boundary_segment_strategy
  Current Config: base_case
--------------------------------------------------
checkpoint_epoch         
  Current Config: None
--------------------------------------------------
compare_current_loaded   
  Current Config: False
--------------------------------------------------
current_epoch            
  Current Config: None
--------------------------------------------------
geometry                 
  Current Config: {'rod_length': 1.0, 'rod_width': 1.0, 'dx': 0.04, 'dy': 0.04}
--------------------------------------------------
io_and_plots             
  Current Config: {'plots': {'movie_frames': False, 'num_examples': 20}, 'model_saving': True}
--------------------------------------------------
learning_rate_schedule   
  Current Config: {5: 0.001, 30: 0.0005, 40: 0.0001, 60: 1e-05, 120: 1e-06}
--------------------------------------------------
model_params             
  Current Config: {'start_predicting_from': 5, 'batch_size': 4, 'epochs': 100, 'time_steps': 401, 'num_heads': 16, 'num_encoder_layers': 24, 'mlp_dim': 256, 'embed_dim': 512, 'mask_type': 'block'}
--------------------------------------------------
run_label                
  Current Config: run_permute_quant_builtin_rope_Kourkoub1
--------------------------------------------------
save_checkpoints         
  Current Config: True
--------------------------------------------------
save_interval            
  Current Config: 350
--------------------------------------------------
scale_schedule           
  Current Config: {0: 0.0, 10: 0.05, 20: 0.0, 30: 0.05, 40: 0.0, 50: 0.01, 60: 0.0, 70: 0.005, 80: 0.0, 90: 0.0001, 100: 0.0, 110: 1e-05, 120: 0.0}
--------------------------------------------------
seed                     
  Current Config: 1
--------------------------------------------------
start_from_scratch       
  Current Config: True
--------------------------------------------------
thermal_diffusivity      
  Current Config: {'alpha_limits': [0.01, 0.1]}
--------------------------------------------------
training_samples         
  Current Config: 4000
--------------------------------------------------
************************ Hostname: PaloAlto Starting Training *********************** 
start_epoch: 0 epochs: 100 learning_rate: 0.0010000000474974513
Epoch 1, lr: 0.0010000000474974513, Training Loss: 0.16154728434447732, Validation Loss: 0.03866139929741621, Number of Train batches: 700, Average sunspike across parameters:", None
Epoch 2, lr: 0.0010000000474974513, Training Loss: 0.03684247444915984, Validation Loss: 0.02266990268137306, Number of Train batches: 700, Average sunspike across parameters:", None
Epoch 3, lr: 0.0010000000474974513, Training Loss: 0.019683061385128115, Validation Loss: 0.011372376414947212, Number of Train batches: 700, Average sunspike across parameters:", None
Epoch 4, lr: 0.0010000000474974513, Training Loss: 0.010809252415451089, Validation Loss: 0.0065572917892131955, Number of Train batches: 700, Average sunspike across parameters:", None
Epoch 5, lr: 0.0010000000474974513, Training Loss: 0.006911905429026644, Validation Loss: 0.0038973533106036484, Number of Train batches: 700, Average sunspike across parameters:", None
Epoch 6, lr: 0.0010000000474974513, Training Loss: 0.003743510142667219, Validation Loss: 0.0017156800703378395, Number of Train batches: 700, Average sunspike across parameters:", None
Epoch 7, lr: 0.0010000000474974513, Training Loss: 0.0028883570134972357, Validation Loss: 0.0016162975816405379, Number of Train batches: 700, Average sunspike across parameters:", None
Epoch 8, lr: 0.0010000000474974513, Training Loss: 0.0020927908806230074, Validation Loss: 0.0021124724467517808, Number of Train batches: 700, Average sunspike across parameters:", None
Epoch 9, lr: 0.0010000000474974513, Training Loss: 0.0019125229678632293, Validation Loss: 0.0013399298618605826, Number of Train batches: 700, Average sunspike across parameters:", None
Epoch 10, lr: 0.0010000000474974513, Training Loss: 0.00147195790499349, Validation Loss: 0.0010072696958377493, Number of Train batches: 700, Average sunspike across parameters:", None
Epoch 11, lr: 0.0010000000474974513, Training Loss: 0.001195197160954454, Validation Loss: 0.0021477033803239463, Number of Train batches: 700, Average sunspike across parameters:", None
Epoch 12, lr: 0.0010000000474974513, Training Loss: 0.0010971888848247805, Validation Loss: 0.0013943305816792417, Number of Train batches: 700, Average sunspike across parameters:", None
Epoch 13, lr: 0.0010000000474974513, Training Loss: 0.0009630109409460732, Validation Loss: 0.0008410365383315366, Number of Train batches: 700, Average sunspike across parameters:", None
Epoch 14, lr: 0.0010000000474974513, Training Loss: 0.0009062093370760392, Validation Loss: 0.0007892103071208112, Number of Train batches: 700, Average sunspike across parameters:", None
Epoch 15, lr: 0.0010000000474974513, Training Loss: 0.0007857939013047144, Validation Loss: 0.0008340868675441016, Number of Train batches: 700, Average sunspike across parameters:", None
Epoch 16, lr: 0.0010000000474974513, Training Loss: 0.0006613926731474099, Validation Loss: 0.0006688903570466209, Number of Train batches: 700, Average sunspike across parameters:", None
Epoch 17, lr: 0.0010000000474974513, Training Loss: 0.0005967419841804907, Validation Loss: 0.0005638139140501153, Number of Train batches: 700, Average sunspike across parameters:", None
Epoch 18, lr: 0.0010000000474974513, Training Loss: 0.00047094482327728266, Validation Loss: 0.0005029825938981957, Number of Train batches: 700, Average sunspike across parameters:", None
Epoch 19, lr: 0.0010000000474974513, Training Loss: 0.0004832804757357475, Validation Loss: 0.00026085366120241814, Number of Train batches: 700, Average sunspike across parameters:", None
Epoch 20, lr: 0.0010000000474974513, Training Loss: 0.0004081047480368787, Validation Loss: 0.0002371868620321038, Number of Train batches: 700, Average sunspike across parameters:", None
Epoch 21, lr: 0.0010000000474974513, Training Loss: 0.00041343536670735505, Validation Loss: 0.000305344103690004, Number of Train batches: 700, Average sunspike across parameters:", None
Epoch 22, lr: 0.0010000000474974513, Training Loss: 0.00036698049631792983, Validation Loss: 0.0002708096142669092, Number of Train batches: 700, Average sunspike across parameters:", None
Epoch 23, lr: 0.0010000000474974513, Training Loss: 0.0004053831810805215, Validation Loss: 0.0004603027447956265, Number of Train batches: 700, Average sunspike across parameters:", None
Epoch 24, lr: 0.0010000000474974513, Training Loss: 0.0003406711126185006, Validation Loss: 0.00032133118809724693, Number of Train batches: 700, Average sunspike across parameters:", None
Epoch 25, lr: 0.0010000000474974513, Training Loss: 0.0003300578930013996, Validation Loss: 0.00028455356863560155, Number of Train batches: 700, Average sunspike across parameters:", None
Epoch 26, lr: 0.0010000000474974513, Training Loss: 0.00030606485979140934, Validation Loss: 0.00025203160097589714, Number of Train batches: 700, Average sunspike across parameters:", None
Epoch 27, lr: 0.0010000000474974513, Training Loss: 0.00033673428445971305, Validation Loss: 0.0001958663332334254, Number of Train batches: 700, Average sunspike across parameters:", None